#!/usr/bin/env python3
"""
è¯„ä¼°è„šæœ¬ï¼šå¯¹æ¯”åŸºçº¿ BioCLIP-2 å’Œ LoRA å¾®è°ƒåçš„æ¨¡å‹
åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œé›¶æ ·æœ¬åˆ†ç±»è¯„ä¼°
"""

import os
import sys
sys.path.insert(0, '/root/bioclip-2/src')

import torch
import pandas as pd
from PIL import Image
from tqdm import tqdm
import numpy as np
from collections import defaultdict

from open_clip import create_model_and_transforms, get_tokenizer
from open_clip.lora import apply_lora_to_model, load_lora_weights

# é…ç½®
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MODEL_NAME = "ViT-L-14"
# è®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹ä½œä¸ºåŸºçº¿
# æˆ–ä½¿ç”¨ laion400m_e31 ä½œä¸ºå‚è€ƒåŸºçº¿
PRETRAINED = None  # ä¸è®­ç»ƒæ—¶ä¸€è‡´
PRETRAINED_BASELINE = "laion400m_e31"  # ä½œä¸ºå‚è€ƒåŸºçº¿
LORA_WEIGHTS_PATH = "/root/bioclip-2/logs/2025_12_16-11_40_22-model_ViT-L-14-lr_0.0005-b_32-j_4-p_bf16/checkpoints/lora_epoch_20.pt"
VAL_DATA_PATH = "/root/bioclip-2/data/val_data.csv"

# LoRA é…ç½®ï¼ˆéœ€è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
LORA_RANK = 8
LORA_ALPHA = 16.0

def load_baseline_model():
    """åŠ è½½åŸºçº¿æ¨¡å‹ (LAION é¢„è®­ç»ƒçš„ CLIP)"""
    print(f"åŠ è½½åŸºçº¿æ¨¡å‹ ({PRETRAINED_BASELINE})...")
    model, _, preprocess = create_model_and_transforms(
        MODEL_NAME,
        pretrained=PRETRAINED_BASELINE
    )
    model = model.to(DEVICE).eval()
    return model, preprocess

def load_lora_model():
    """åŠ è½½å¸¦æœ‰ LoRA æƒé‡çš„æ¨¡å‹ï¼ˆä¸è®­ç»ƒé…ç½®ä¸€è‡´ï¼‰"""
    print("åŠ è½½ LoRA å¾®è°ƒåçš„æ¨¡å‹...")
    # æ³¨æ„ï¼šè®­ç»ƒæ—¶æ²¡æœ‰ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œè¿™é‡Œä¹Ÿä¿æŒä¸€è‡´
    model, _, preprocess = create_model_and_transforms(
        MODEL_NAME,
        pretrained=PRETRAINED  # None - ä¸è®­ç»ƒæ—¶ä¸€è‡´
    )
    
    # åº”ç”¨ LoRA
    model, _ = apply_lora_to_model(
        model, 
        rank=LORA_RANK, 
        alpha=LORA_ALPHA,
        enable_vision=True,
        enable_text=True
    )
    
    # åŠ è½½ LoRA æƒé‡
    load_lora_weights(model, LORA_WEIGHTS_PATH)
    model = model.to(DEVICE).eval()
    return model, preprocess


def load_random_baseline():
    """åŠ è½½ä¸è®­ç»ƒé…ç½®ä¸€è‡´çš„éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆæ— LoRAï¼Œæ— é¢„è®­ç»ƒï¼‰"""
    print("åŠ è½½éšæœºåˆå§‹åŒ–æ¨¡å‹ (æ— é¢„è®­ç»ƒï¼Œä½œä¸ºè®­ç»ƒèµ·ç‚¹å‚è€ƒ)...")
    model, _, preprocess = create_model_and_transforms(
        MODEL_NAME,
        pretrained=None
    )
    model = model.to(DEVICE).eval()
    return model, preprocess

def get_class_names(df):
    """è·å–ç±»åˆ«åç§°åˆ—è¡¨"""
    return sorted(df['caption'].unique().tolist())

def create_text_features(model, tokenizer, class_names):
    """ä¸ºæ‰€æœ‰ç±»åˆ«åˆ›å»ºæ–‡æœ¬ç‰¹å¾"""
    # ä½¿ç”¨ç®€å•çš„æ¨¡æ¿
    templates = [
        "a photo of {}",
        "an image of {}",
        "{}"
    ]
    
    text_features_list = []
    
    with torch.no_grad():
        for class_name in class_names:
            class_features = []
            for template in templates:
                text = template.format(class_name)
                tokens = tokenizer([text]).to(DEVICE)
                features = model.encode_text(tokens)
                features = features / features.norm(dim=-1, keepdim=True)
                class_features.append(features)
            
            # å¹³å‡æ‰€æœ‰æ¨¡æ¿çš„ç‰¹å¾
            avg_features = torch.stack(class_features).mean(dim=0)
            avg_features = avg_features / avg_features.norm(dim=-1, keepdim=True)
            text_features_list.append(avg_features)
    
    text_features = torch.cat(text_features_list, dim=0)
    return text_features

def evaluate_model(model, preprocess, tokenizer, df, class_names, model_name="Model"):
    """è¯„ä¼°æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„æ€§èƒ½"""
    print(f"\nè¯„ä¼° {model_name}...")
    
    # åˆ›å»ºæ–‡æœ¬ç‰¹å¾
    text_features = create_text_features(model, tokenizer, class_names)
    
    correct_top1 = 0
    correct_top5 = 0
    total = 0
    
    # æ¯ä¸ªç±»åˆ«çš„ç»Ÿè®¡
    class_correct = defaultdict(int)
    class_total = defaultdict(int)
    
    # å­˜å‚¨æ‰€æœ‰é¢„æµ‹ç»“æœ
    all_predictions = []
    
    with torch.no_grad():
        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f"è¯„ä¼° {model_name}"):
            filepath = row['filepath']
            true_label = str(row['caption'])
            
            try:
                # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
                image = Image.open(filepath).convert('RGB')
                image_input = preprocess(image).unsqueeze(0).to(DEVICE)
                
                # è·å–å›¾åƒç‰¹å¾
                image_features = model.encode_image(image_input)
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)
                
                # Top-1 å’Œ Top-5 é¢„æµ‹
                values, indices = similarity[0].topk(5)
                top1_pred = class_names[indices[0].item()]
                top5_preds = [class_names[i.item()] for i in indices]
                
                # ç»Ÿè®¡å‡†ç¡®ç‡
                if top1_pred == true_label:
                    correct_top1 += 1
                    class_correct[true_label] += 1
                
                if true_label in top5_preds:
                    correct_top5 += 1
                
                class_total[true_label] += 1
                total += 1
                
                all_predictions.append({
                    'filepath': filepath,
                    'true_label': true_label,
                    'pred_label': top1_pred,
                    'confidence': values[0].item(),
                    'correct': top1_pred == true_label
                })
                
            except Exception as e:
                print(f"å¤„ç† {filepath} æ—¶å‡ºé”™: {e}")
                continue
    
    # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
    top1_acc = correct_top1 / total * 100
    top5_acc = correct_top5 / total * 100
    
    print(f"\n{model_name} ç»“æœ:")
    print(f"  Top-1 å‡†ç¡®ç‡: {top1_acc:.2f}%")
    print(f"  Top-5 å‡†ç¡®ç‡: {top5_acc:.2f}%")
    print(f"  æ€»æ ·æœ¬æ•°: {total}")
    
    # æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    print(f"\n  å„ç±»åˆ« Top-1 å‡†ç¡®ç‡:")
    for class_name in class_names:
        if class_total[class_name] > 0:
            acc = class_correct[class_name] / class_total[class_name] * 100
            print(f"    {class_name}: {acc:.2f}% ({class_correct[class_name]}/{class_total[class_name]})")
    
    return {
        'top1_acc': top1_acc,
        'top5_acc': top5_acc,
        'total': total,
        'class_acc': {c: class_correct[c]/class_total[c]*100 if class_total[c] > 0 else 0 for c in class_names},
        'predictions': all_predictions
    }

def main():
    print("="*60)
    print("LoRA å¾®è°ƒéªŒè¯è¯„ä¼°")
    print("="*60)
    
    # åŠ è½½éªŒè¯æ•°æ®
    print(f"\nåŠ è½½éªŒè¯æ•°æ®: {VAL_DATA_PATH}")
    df = pd.read_csv(VAL_DATA_PATH, sep='\t')
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(df)}")
    
    class_names = get_class_names(df)
    print(f"ç±»åˆ«æ•°: {len(class_names)}")
    print(f"ç±»åˆ«: {class_names}")
    
    # åŠ è½½ tokenizer
    tokenizer = get_tokenizer(MODEL_NAME)
    
    results = {}
    
    # 1. è¯„ä¼° LAION é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹
    print("\n" + "-"*40)
    baseline_model, preprocess = load_baseline_model()
    results['laion_baseline'] = evaluate_model(
        baseline_model, preprocess, tokenizer, df, class_names,
        model_name=f"LAIONé¢„è®­ç»ƒåŸºçº¿ ({PRETRAINED_BASELINE})"
    )
    del baseline_model
    torch.cuda.empty_cache()
    
    # 2. è¯„ä¼°éšæœºåˆå§‹åŒ–æ¨¡å‹ï¼ˆè®­ç»ƒèµ·ç‚¹å‚è€ƒï¼‰
    print("\n" + "-"*40)
    random_model, preprocess = load_random_baseline()
    results['random_init'] = evaluate_model(
        random_model, preprocess, tokenizer, df, class_names,
        model_name="éšæœºåˆå§‹åŒ–æ¨¡å‹ (è®­ç»ƒèµ·ç‚¹)"
    )
    del random_model
    torch.cuda.empty_cache()
    
    # 3. è¯„ä¼° LoRA å¾®è°ƒåçš„æ¨¡å‹
    print("\n" + "-"*40)
    lora_model, preprocess = load_lora_model()
    results['lora'] = evaluate_model(
        lora_model, preprocess, tokenizer, df, class_names,
        model_name="LoRA å¾®è°ƒæ¨¡å‹ (20 epochs)"
    )
    
    # å¯¹æ¯”ç»“æœ
    print("\n" + "="*60)
    print("å¯¹æ¯”ç»“æœæ€»ç»“")
    print("="*60)
    
    print(f"\n{'æ¨¡å‹':<35} {'Top-1 å‡†ç¡®ç‡':<15} {'Top-5 å‡†ç¡®ç‡':<15}")
    print("-"*65)
    print(f"{'LAIONé¢„è®­ç»ƒåŸºçº¿':<35} {results['laion_baseline']['top1_acc']:<15.2f} {results['laion_baseline']['top5_acc']:<15.2f}")
    print(f"{'éšæœºåˆå§‹åŒ– (è®­ç»ƒèµ·ç‚¹)':<35} {results['random_init']['top1_acc']:<15.2f} {results['random_init']['top5_acc']:<15.2f}")
    print(f"{'LoRAå¾®è°ƒå':<35} {results['lora']['top1_acc']:<15.2f} {results['lora']['top5_acc']:<15.2f}")
    
    # è®¡ç®—æå‡
    improvement_from_random = results['lora']['top1_acc'] - results['random_init']['top1_acc']
    print(f"\nğŸ“ˆ LoRA å¾®è°ƒæå‡ (vs éšæœºåˆå§‹åŒ–): {'+' if improvement_from_random >= 0 else ''}{improvement_from_random:.2f}%")
    
    # ä¿å­˜ç»“æœ
    results_path = "/root/bioclip-2/logs/evaluation_results.txt"
    with open(results_path, 'w') as f:
        f.write("LoRA å¾®è°ƒéªŒè¯è¯„ä¼°ç»“æœ\n")
        f.write("="*60 + "\n\n")
        f.write(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(df)}\n")
        f.write(f"ç±»åˆ«æ•°: {len(class_names)}\n")
        f.write(f"ç±»åˆ«: {class_names}\n\n")
        
        f.write(f"1. LAIONé¢„è®­ç»ƒåŸºçº¿ ({PRETRAINED_BASELINE}):\n")
        f.write(f"   Top-1 å‡†ç¡®ç‡: {results['laion_baseline']['top1_acc']:.2f}%\n")
        f.write(f"   Top-5 å‡†ç¡®ç‡: {results['laion_baseline']['top5_acc']:.2f}%\n\n")
        
        f.write(f"2. éšæœºåˆå§‹åŒ–æ¨¡å‹ (è®­ç»ƒèµ·ç‚¹):\n")
        f.write(f"   Top-1 å‡†ç¡®ç‡: {results['random_init']['top1_acc']:.2f}%\n")
        f.write(f"   Top-5 å‡†ç¡®ç‡: {results['random_init']['top5_acc']:.2f}%\n\n")
        
        f.write(f"3. LoRA å¾®è°ƒæ¨¡å‹ (20 epochs):\n")
        f.write(f"   Top-1 å‡†ç¡®ç‡: {results['lora']['top1_acc']:.2f}%\n")
        f.write(f"   Top-5 å‡†ç¡®ç‡: {results['lora']['top5_acc']:.2f}%\n\n")
        
        f.write(f"æå‡ (LoRA vs éšæœºåˆå§‹åŒ–): {'+' if improvement_from_random >= 0 else ''}{improvement_from_random:.2f}%\n")
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    
    return results

if __name__ == "__main__":
    main()

